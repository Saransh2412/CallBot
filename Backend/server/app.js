const express = require('express');
const cors = require('cors');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const speech = require('@google-cloud/speech');

const app = express();

// Google Cloud Speech client
const speechClient = new speech.SpeechClient({
  keyFilename: path.join(__dirname, 'audiobot-462717-e84c749fcbaf.json')
});

// Middleware
app.use(cors());
app.use(express.json());

// Ensure uploads directory exists
const uploadsDir = path.join(__dirname, 'uploads');
if (!fs.existsSync(uploadsDir)) {
  fs.mkdirSync(uploadsDir);
}

// Serve static files (for audio playback and text files)
app.use('/uploads', express.static(uploadsDir));

// Multer setup for audio uploads
const upload = multer({ dest: uploadsDir });

// Health check route
app.get('/', (req, res) => {
  res.send('API is running...');
});

// Upload & transcribe audio route
app.post('/api/audio', upload.single('audio'), async (req, res) => {
  try {
    const ext = '.webm'; // Adjust if using other formats
    const tempPath = path.join(uploadsDir, req.file.filename);
    const finalFilename = req.file.filename + ext;
    const finalPath = path.join(uploadsDir, finalFilename);

    // Rename file to add extension
    fs.renameSync(tempPath, finalPath);
    console.log('üéôÔ∏è Audio file saved at:', finalPath);

    // Convert audio to base64
    const audioBytes = fs.readFileSync(finalPath).toString('base64');

    // Prepare Google Speech config
    const audio = { content: audioBytes };
    const config = {
      encoding: 'WEBM_OPUS',
      languageCode: 'en-US',
      model: 'latest_long'

    };
    const request = { audio, config };

    // Call Google Speech-to-Text API
    const [response] = await speechClient.recognize(request);
    const transcription = response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');

    // Save transcription as a text file
    const textFilename = req.file.filename + '_transcription.txt';
    const textFilePath = path.join(uploadsDir, textFilename);
    
    // Create readable content with metadata
    const textContent = `Audio Transcription
==================
File: ${finalFilename}
Date: ${new Date().toLocaleString()}
Duration: Audio file processed
Language: English (US)

Transcription:
--------------
${transcription || 'No speech detected in the audio file.'}

---
Generated by Audio Transcription API`;

    // Write the text file
    fs.writeFileSync(textFilePath, textContent, 'utf8');
    console.log('üìù Transcription saved at:', textFilePath);

    res.json({
      success: true,
      message: 'Audio transcribed successfully!',
      transcription,
      fileUrl: `http://localhost:5000/uploads/${finalFilename}`,
      textFileUrl: `http://localhost:5000/uploads/${textFilename}`,
      textFilePath: textFilePath
    });

  } catch (error) {
    console.error('‚ùå Error processing audio:', error);
    res.status(500).json({
      success: false,
      message: 'Error processing audio file',
      error: error.message
    });
  }
});

// Route to get list of transcription files
app.get('/api/transcriptions', (req, res) => {
  try {
    const files = fs.readdirSync(uploadsDir);
    const textFiles = files
      .filter(file => file.endsWith('_transcription.txt'))
      .map(file => ({
        filename: file,
        url: `http://localhost:5000/uploads/${file}`,
        created: fs.statSync(path.join(uploadsDir, file)).birthtime
      }))
      .sort((a, b) => new Date(b.created) - new Date(a.created));

    res.json({
      success: true,
      files: textFiles
    });
  } catch (error) {
    console.error('‚ùå Error getting transcription files:', error);
    res.status(500).json({
      success: false,
      message: 'Error retrieving transcription files',
      error: error.message
    });
  }
});

module.exports = app;
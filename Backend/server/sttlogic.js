const fs = require('fs');
const path = require('path');
const speech = require('@google-cloud/speech');
const extractIntentEntities = require('./nlu'); // ‚Üê Add this line
require('dotenv').config();

// Google Speech Client
const speechClient = new speech.SpeechClient({
  keyFilename: path.join(__dirname, 'striped-device-456606-s4-77f1eedb1e8e.json')
});

const uploadsDir = path.join(__dirname, 'uploads');

// Handle audio upload & transcription + NLU
const handleAudioUpload = async (req, res) => {
  try {
    const finalFilename = req.file.filename;
    const finalPath = path.join(uploadsDir, finalFilename);
    console.log('üéôÔ∏è Audio file saved at:', finalPath);

    const audioBytes = fs.readFileSync(finalPath).toString('base64');
    const request = {
      audio: { content: audioBytes },
      config: {
        encoding: 'WEBM_OPUS',
        languageCode: 'en-US',
        model: 'latest_long'
      }
    };

    const [response] = await speechClient.recognize(request);
    const transcription = response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');

    const textFilename = finalFilename + '_transcription.txt';
    const textFilePath = path.join(uploadsDir, textFilename);

    const textContent = `Audio Transcription
==================
File: ${finalFilename}
Date: ${new Date().toLocaleString()}
Duration: Audio file processed
Language: English (US)

Transcription:
--------------
${transcription || 'No speech detected in the audio file.'}

---
Generated by Audio Transcription API`;

    fs.writeFileSync(textFilePath, textContent, 'utf8');
    console.log('üìù Transcription saved at:', textFilePath);

    // üîç Extract intent + entities using NLU
    let nluResult = {};
    if (transcription) {
      try {
        nluResult = await extractIntentEntities(transcription);
        console.log('ü§ñ NLU Result:', nluResult);
      } catch (nluError) {
        console.error('‚ùå Error in NLU:', nluError.message);
        nluResult = { error: 'Failed to extract intent/entities' };
      }
    }

    res.json({
      success: true,
      message: 'Audio transcribed and analyzed successfully!',
      transcription,
      nlu: nluResult,
      fileUrl: `http://localhost:5000/uploads/${finalFilename}`,
      textFileUrl: `http://localhost:5000/uploads/${textFilename}`,
      textFilePath: textFilePath
    });

  } catch (error) {
    console.error('‚ùå Error processing audio:', error);
    res.status(500).json({
      success: false,
      message: 'Error processing audio file',
      error: error.message
    });
  }
};

// Get list of transcriptions
const getTranscriptions = (req, res) => {
  try {
    const files = fs.readdirSync(uploadsDir);
    const textFiles = files
      .filter(file => file.endsWith('_transcription.txt'))
      .map(file => ({
        filename: file,
        url: `http://localhost:5000/uploads/${file}`,
        created: fs.statSync(path.join(uploadsDir, file)).birthtime
      }))
      .sort((a, b) => new Date(b.created) - new Date(a.created));

    res.json({
      success: true,
      files: textFiles
    });
  } catch (error) {
    console.error('‚ùå Error getting transcription files:', error);
    res.status(500).json({
      success: false,
      message: 'Error retrieving transcription files',
      error: error.message
    });
  }
};

module.exports = {
  handleAudioUpload,
  getTranscriptions
};
